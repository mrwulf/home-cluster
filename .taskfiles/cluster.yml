---
version: "3"

tasks:
  k10-password:
    desc: Retrieve the grafana admin password
    silent: true
    cmds:
      - kubectl -n backups get secret $(kubectl -n backups get serviceaccount k10-k10 -o jsonpath="{.secrets[0].name}") -ojsonpath="{.data.token}" | base64 --decode && echo

  grafana-password:
    desc: Retrieve the grafana admin password
    silent: true
    cmds:
      - kubectl -n monitoring get secret kube-prometheus-stack-grafana -ojsonpath="{.data.admin-password}" | base64 --decode && echo

  postgres-password:
    desc: Retrieve the postgres admin password
    silent: true
    cmds:
      - kubectl -n databases get secret postgres-superuser -ojsonpath="{.data.password}" | base64 --decode && echo

  why-dockerhub:
    desc: What dockerhub images are running in my cluster
    silent: true
    cmds:
      - kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{'\n'}{range .spec.containers[*]}{.image}{'\n'}{end}{end}" | sort | uniq | grep -Ev 'quay|gcr|ghcr|ecr|us-docker' | grep -Ev 'bitnami|rook|intel|grafana' |  sed -e 's/docker\.io\///g' | sort | uniq

  list-all-images:
    desc: List all images running in the cluster
    silent: true
    cmds:
      - kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}" |tr -s '[[:space:]]' '\n' | sort | uniq

  delete-failed-pods:
    desc: Deletes failed pods
    cmds:
      - kubectl delete pods --field-selector status.phase=Failed -A --ignore-not-found=true

  delete-completed-pods:
    desc: Deletes completed pods
    cmds:
      - kubectl delete pods --field-selector status.phase=Succeeded -A --ignore-not-found=true

  cleanup:
    desc: Deletes finished pods
    cmds:
      - task: delete-failed-pods
      - task: delete-completed-pods

  list-nfs-workloads:
    desc: List all deployments with NFS volumes
    silent: true
    cmds:
      - kubectl get sts,deploy -A -o=json | jq -r '[.items[] | select(.spec.template.spec.volumes[]?.nfs) |  [(.metadata.namespace|@sh), (.kind + "/" + .metadata.name|@sh) ]] | unique | flatten | .[] ' | xargs -l2 echo

  list-nfs-pods:
    desc: List all deployments with NFS volumes
    silent: true
    cmds:
      - kubectl get pods -A -o=json | jq -r '[.items[] | select(.spec.volumes[]?.nfs) |  [(.metadata.namespace|@sh), (.metadata.name|@sh) ]] | unique | flatten | .[] ' | xargs -l2 echo

  scale-nfs-workloads-down:
    desc: Scale all deployments with NFS volumes down to zero
    silent: true
    cmds:
      - kubectl get sts,deploy -A -o=json | jq -r '[.items[] | select(.spec.template.spec.volumes[]?.nfs) |  [(.metadata.namespace|@sh), (.kind + "/" + .metadata.name|@sh) ]] | unique | flatten | .[] ' | xargs -l2 kubectl scale --replicas=0 -n

  scale-nfs-workloads-up:
    desc: Scale all deployments with NFS volumes to one
    silent: true
    cmds:
      - kubectl get sts,deploy -A -o=json | jq -r '[.items[] | select(.spec.template.spec.volumes[]?.nfs) |  [(.metadata.namespace|@sh), (.kind + "/" + .metadata.name|@sh) ]] | unique | flatten | .[] ' | xargs -l2 kubectl scale --replicas=1 -n
      - kubectl -n household scale deploy immich-server --replicas 2
      - kubectl -n household scale deploy immich-microservices --replicas 4

  rebalance:
    desc: Run the descheduler to rebalance pods
    silent: true
    cmds:
      - kubectl -n system create job rebalance-`date '+%H%M%d'` --from=cronjob/descheduler

  watch:
    desc: Watch the cluster
    aliases:
      - :watch
    interactive: true
    cmds:
      - watch -n2 "kubectl get po -A -owide | grep -v Running && echo '' && kubectl get ks -A | grep -v Applied && echo '' && kubectl get hr -A | grep -v succeeded"
