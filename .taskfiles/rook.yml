---
version: "3"


vars:
  NAMESPACE: storage
  POOL: ceph-block
  VOLUMESNAPSHOTCLASS: csi-rbdplugin-snapclass

tasks:
  toolbox:
    desc: Exec into the Rook Ceph toolbox
    interactive: true
    cmds:
      - kubectl -n {{.NAMESPACE}} exec -it $(kubectl -n {{.NAMESPACE}} get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- bash
    silent: true

  rook-password:
    desc: Retrieve the rook-ceph password
    silent: true
    cmds:
      - kubectl -n {{.NAMESPACE}} get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode && echo

# Clean up everything: for this_img in `kubectl get pv --sort-by=metadata.creationTimestamp | grep Released | grep backups/kanister | awk '{print $1}'`; do task rook:clean-up-pv -- $this_img ; done
  clean-up-pv:
    desc: Clean a single PV
    requires:
      vars: ["PV"]
    vars:
      PVNAME: '{{.PV | default "invalid"}}'
      IMG:
        sh: kubectl describe pv {{.PVNAME}} | grep imageName | awk -F= '{print $2}'
      CHILDREN:
        sh: kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd children --all -p {{.POOL}} {{.IMG}} | tr '\n' ',' | head -c -1
    cmds:
      - |
        echo -e "PVNAME: {{.PVNAME}}\nIMG: {{.IMG}}"
        if [ -z "{{.CHILDREN}}" ]; then
          kubectl get pv {{.PVNAME}}
          kubectl delete pv {{.PVNAME}}
          kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd rm -p {{.POOL}} {{.IMG}}
        else
          echo "Ignoring: This volume still has children! ({{.CHILDREN}})"
        fi
    preconditions:
      - sh: kubectl get po -n {{.NAMESPACE}} -lapp=rook-ceph-tools | grep -q Running
        msg: Rook tools pod isn't running.
      # - sh: '[ -z "{{.CHILDREN}}" ]'
      #   msg: "These children must be removed first: (probably volumesnapshots)\n{{.CHILDREN}}"
        # Delete most of the older children: kubectl get volumesnapshot --sort-by='.status.creationTime' -A | grep -v backups | grep -P 'd$' | awk '{print $1, $2}' | xargs -r -L1  kubectl  delete volumesnapshot -n

  clean-up-all-pv:
    desc: Clean up all PVs
    vars:
      PV_LIST:
        sh: kubectl get pv --no-headers | grep -v Bound | awk '{print $1}' | tr '\n' ',' | head -c -1
    cmds:
      - for: { var: PV_LIST, split: ",", as: PV }
        task: clean-up-pv
        vars:
          PV: '{{.PV}}'

  clean-up-img:
    desc: Clean up an image
    vars:
      IMG: "{{.CLI_ARGS}}"
      CHILDREN:
        sh: kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd children --all -p {{.POOL}} {{.IMG}}
    cmds:
      - |
        # kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd snap purge -p {{.POOL}} {{.IMG}}
        kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd rm -p {{.POOL}} {{.IMG}}
    preconditions:
      - sh: kubectl get po -n {{.NAMESPACE}} -lapp=rook-ceph-tools | grep -q Running
        msg: Rook tools pod isn't running.
      - sh: '[ -n "{{.CLI_ARGS}}" ]'
        msg: 'Image Name Required!'
      - sh: '[ -z "{{.CHILDREN}}" ]'
        msg: "These children must be removed first:\n {{.CHILDREN}}"


# Purge retained volumesnapshots & volumesnapshotcontents from backups NS (k10)
# for SN in $(k get volumesnapshotcontents.snapshot.storage.k8s.io | grep Retain | awk '{print $1}'); do echo $SN; VS=$(kubectl get volumesnapshotcontents.snapshot.storage.k8s.io $SN -ojsonpath='{.spec.volumeSnapshotRef.name}'); echo $VS; kubectl delete volumesnapshot $VS -n backups;  kubectl delete volumesnapshotcontents $SN; done

# still have snapshots:
# csi-vol-677a4f42-f91a-11ec-bc39-0ed6f0913b1b
# csi-vol-677b530e-f91a-11ec-bc39-0ed6f0913b1b

  get-unused-images:
    desc: Collect unused images
    silent: true
    cmds:
      - |
        kubectl exec -n {{.NAMESPACE}} -it $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- rbd -p {{.POOL}} ls | grep 'csi-vol-' > image_list.txt
        for PV in $(kubectl get pv | grep {{.POOL}} | awk '{print $1}'); do
          IMG=$(kubectl describe pv $PV | grep imageName | awk -F= '{print $2}')
          if (! grep -q $IMG image_list.txt); then
            echo "$IMG not in image_list.txt"
          fi
          sed -i "/${IMG}/d" image_list.txt
        done
        echo "Results in image_list.txt:"
        cat image_list.txt

  ack-warnings:
    desc: Archive all ceph crashes
    silent: true
    cmds:
      - kubectl exec -n {{.NAMESPACE}} $(kubectl get po -A -lapp=rook-ceph-tools -oname) -- ceph crash archive-all

  debug-pvc:
    desc: Attach a volume to a container for debugging, ex. VOLUME=zigbee2mqtt-config-v1 task debug-volume
    interactive: true
    silent: false
    vars:
      # VOLUME: "{{.CLI_ARGS}}"
      VOL:
        sh: "echo {{.VOLUME}} | cut -c -52"
      NAMESPACE:
        sh: "kubectl get pvc -A | grep {{.VOLUME}} | awk '{print $1; exit}'"
      NAS_ADDRESS:
        sh: "sops --decrypt cluster/base/cluster-secrets.sops.yaml | yq '.stringData.CORE_NFS_SERVER'"
      NAS_PATH:
        sh: "sops --decrypt cluster/base/cluster-secrets.sops.yaml | yq '.stringData.NFS_KUBERNETES_PATH'"
    preconditions:
      - sh: '[ -n "{{.VOL}}" ]'
        msg: 'PVC Name Required!'
    cmds:
      - |
        kubectl run debug-pvc-{{.VOL}} -n {{.NAMESPACE}} -it --image=null --overrides='
          {
            "spec": {
              "containers": [
                {
                  "name": "debug",
                  "image": "docker.io/library/alpine:3.15",
                  "command": [
                    "/bin/sh"
                  ],
                  "stdin": true,
                  "stdinOnce": true,
                  "tty": true,
                  "lifecycle": {
                    "postStart": {
                      "exec": {
                        "command": [
                          "/bin/sh",
                          "-c",
                          "apk add --no-cache curl vim rsync &"
                        ]
                      }
                    }
                  },
                  "volumeMounts": [
                    {
                      "name": "backups",
                      "mountPath": "/mnt/backups/"
                    },
                    {
                      "name": "debug-volume",
                      "mountPath": "/mnt/volume/"
                    }
                  ]
                }
              ],
              "volumes": [
                {
                  "name": "backups",
                  "nfs": {
                    "server": "{{.NAS_ADDRESS}}",
                    "path": "{{.NAS_PATH}}"
                  }
                },
                {
                  "name": "debug-volume",
                  "persistentVolumeClaim": {
                    "claimName": "{{.VOLUME}}"
                  }
                }
              ],
              "restartPolicy": "Never"
            }
          }'

  browse-volume-snapshot:
    desc: Clone a volume snapshot and then attach and start a little file browser web app. Press ctrl+c to kill browser
    interactive: true
    vars:
      PVC: '{{.CLI_ARGS}}'
      NAMESPACE:
        sh: 'kubectl get pvc -A -oyaml | yq ''.items[] | select(.metadata.name=="{{.PVC}}") | .metadata.namespace'''
    cmds:
      - kubestr browse {{.PVC}} -n {{.NAMESPACE}} -v {{.VOLUMESNAPSHOTCLASS}}
      - echo "Don't forget to delete the left over PV"
